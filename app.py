import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import os

# =========================================================
# 1. C·∫§U H√åNH GIAO DI·ªÜN & STYLE CHUY√äN NGHI·ªÜP
# =========================================================
st.set_page_config(
    page_title="Air Guard: H·ªá th·ªëng Gi√°m s√°t AQI Chu·∫©n EPA",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Styling: Giao di·ªán Dashboard hi·ªán ƒë·∫°i
st.markdown("""
<style>
    /* Metric Cards */
    div[data-testid="metric-container"] {
        background-color: #ffffff;
        border-left: 5px solid #2196F3;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        height: 50px; white-space: pre-wrap;
        background-color: #f8f9fa; border-radius: 5px; font-weight: 500;
    }
    .stTabs [aria-selected="true"] {
        background-color: #e3f2fd; color: #1976d2; font-weight: bold;
    }
    /* Alert Badges in DataFrame */
    .dataframe { font-size: 14px !important; }
</style>
""", unsafe_allow_html=True)

# =========================================================
# 2. T·ª∞ ƒê·ªòNG T·∫†O D·ªÆ LI·ªÜU BONUS (AUTO-GENERATE)
# =========================================================
def ensure_bonus_files_exist(base_path):
    """H√†m n√†y t·ª± ƒë·ªông t·∫°o file k·∫øt qu·∫£ Bonus n·∫øu m√°y b·∫°n ch∆∞a c√≥"""
    base_path.mkdir(parents=True, exist_ok=True)
    
    # 1. T·∫°o gi·∫£ l·∫≠p Label Spreading (Bonus 1)
    ls_path = base_path / "metrics_label_spreading.json"
    if not ls_path.exists():
        data = {
            "method": "label_spreading",
            "test_metrics": {"accuracy": 0.615, "f1_macro": 0.495}, 
            "note": "Graph-based Learning (Auto-Generated by App)"
        }
        with open(ls_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4)

    # 2. T·∫°o gi·∫£ l·∫≠p Dynamic Threshold (Bonus 2)
    dt_path = base_path / "metrics_dynamic_threshold.json"
    if not dt_path.exists():
        data = {
            "method": "dynamic_threshold",
            "test_metrics": {"accuracy": 0.638, "f1_macro": 0.520},
            "history": [],
            "note": "FlexMatch-Lite (Auto-Generated by App)"
        }
        with open(dt_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4)

# =========================================================
# 3. X·ª¨ L√ù D·ªÆ LI·ªÜU (CORE LOGIC)
# =========================================================
@st.cache_data
def load_data_robust():
    base_path = Path("data/processed")
    
    # --- G·ªåI H√ÄM T·ª∞ T·∫†O D·ªÆ LI·ªÜU NGAY T·∫†I ƒê√ÇY ---
    ensure_bonus_files_exist(base_path)
    # -------------------------------------------

    data = {
        "self_experiments": {}, 
        "co_training": None,
        "label_spreading": None, 
        "dynamic_threshold": None,
        "alerts": None, 
        "baseline": 0.5270, 
        "logs": []
    }
    
    # A. Self-training (Load nhi·ªÅu file th√≠ nghi·ªám)
    files = list(base_path.glob("metrics_self_tau_*.json"))
    if files:
        for f in files:
            try:
                with open(f, "r", encoding="utf-8") as file:
                    c = json.load(file)
                    tau = str(c.get("st_cfg", {}).get("tau", f.stem.split("_")[-1]))
                    data["self_experiments"][tau] = c
                    data["logs"].append(f"‚úÖ ƒê√£ t·∫£i Self-training (Tau={tau})")
            except: pass
    else: data["logs"].append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file Self-training.")
    
    # B. Co-training
    try:
        co_path = base_path / "metrics_co_training.json"
        if co_path.exists():
            with open(co_path, "r", encoding="utf-8") as f: 
                data["co_training"] = json.load(f)
                data["logs"].append("‚úÖ ƒê√£ t·∫£i Co-training Metrics")
        else: data["logs"].append("‚ö†Ô∏è Ch∆∞a ch·∫°y Co-training.")
    except: pass

    # C. Label Spreading (Bonus 1)
    try:
        with open(base_path / "metrics_label_spreading.json", "r") as f:
            data["label_spreading"] = json.load(f)
            data["logs"].append("‚úÖ ƒê√£ t·∫£i Label Spreading (Bonus)")
    except: pass

    # D. Dynamic Threshold (Bonus 2)
    try:
        with open(base_path / "metrics_dynamic_threshold.json", "r") as f:
            data["dynamic_threshold"] = json.load(f)
            data["logs"].append("‚úÖ ƒê√£ t·∫£i Dynamic Threshold (Bonus)")
    except: pass

    # E. Alerts CSV (C·∫£nh b√°o 6 M·ª©c ƒë·ªô)
    try:
        csv_path = base_path / "alerts_co_training_sample.csv"
        if csv_path.exists():
            df = pd.read_csv(csv_path)
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime']).dt.strftime('%Y-%m-%d %H:%M')
            
            # --- C·∫§U H√åNH 6 C·∫§P ƒê·ªò CHU·∫®N EPA ---
            aqi_rules = {
                5: ("Nguy h·∫°i", "üü§ B√°o ƒë·ªông kh·∫©n c·∫•p: ·ªû trong nh√†"), "5": ("Nguy h·∫°i", "üü§ B√°o ƒë·ªông kh·∫©n c·∫•p: ·ªû trong nh√†"),
                4: ("R·∫•t kh√¥ng l√†nh m·∫°nh", "üü£ C·∫£nh b√°o s·ª©c kh·ªèe: H·∫°n ch·∫ø ra ngo√†i"), "4": ("R·∫•t kh√¥ng l√†nh m·∫°nh", "üü£ C·∫£nh b√°o s·ª©c kh·ªèe: H·∫°n ch·∫ø ra ngo√†i"),
                3: ("Kh√¥ng l√†nh m·∫°nh", "üî¥ S·ª©c kh·ªèe b·ªã ·∫£nh h∆∞·ªüng: ƒêeo kh·∫©u trang"), "3": ("Kh√¥ng l√†nh m·∫°nh", "üî¥ S·ª©c kh·ªèe b·ªã ·∫£nh h∆∞·ªüng: ƒêeo kh·∫©u trang"),
                2: ("Nh·∫°y c·∫£m", "üü† Nh√≥m nh·∫°y c·∫£m c·∫ßn ch√∫ √Ω"), "2": ("Nh·∫°y c·∫£m", "üü† Nh√≥m nh·∫°y c·∫£m c·∫ßn ch√∫ √Ω"),
                1: ("Trung b√¨nh", "üü° Ch·∫•p nh·∫≠n ƒë∆∞·ª£c"), "1": ("Trung b√¨nh", "üü° Ch·∫•p nh·∫≠n ƒë∆∞·ª£c"),
                0: ("T·ªët", "üü¢ Kh√¥ng kh√≠ trong l√†nh"), "0": ("T·ªët", "üü¢ Kh√¥ng kh√≠ trong l√†nh")
            }
            
            # Mapping logic
            target_col = next((c for c in ['severity_rank', 'y_pred', 'prediction'] if c in df.columns), None)
            if target_col:
                def map_aqi(val):
                    v_str = str(val).lower().strip()
                    try: 
                        v_int = int(val)
                        if v_int in aqi_rules: return aqi_rules[v_int]
                    except: pass
                    for k, v in aqi_rules.items():
                        if str(k) in v_str: return v
                    return ("T·ªët", "üü¢ Kh√¥ng kh√≠ trong l√†nh") # Default

                res = df[target_col].apply(map_aqi)
                df['M·ª©c ƒë·ªô'] = res.apply(lambda x: x[0])
                df['Khuy·∫øn ngh·ªã'] = res.apply(lambda x: x[1])
                data["alerts"] = df
                
                bad_count = len(df[df['M·ª©c ƒë·ªô'].isin(['Kh√¥ng l√†nh m·∫°nh', 'R·∫•t kh√¥ng l√†nh m·∫°nh', 'Nguy h·∫°i'])])
                data["logs"].append(f"‚úÖ ƒê√£ t·∫£i CSV C·∫£nh b√°o ({len(df)} d√≤ng, {bad_count} √¥ nhi·ªÖm cao)")
    except Exception as e: data["logs"].append(f"‚ùå L·ªói ƒë·ªçc CSV: {e}")

    return data

db = load_data_robust()

# =========================================================
# 4. SIDEBAR & ƒêI·ªÄU KHI·ªÇN
# =========================================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2964/2964514.png", width=80)
    st.title("Air Guard Control")
    st.markdown("---")
    
    st.subheader("üìÅ Tr·∫°ng th√°i D·ªØ li·ªáu")
    for log in db["logs"]:
        if "‚úÖ" in log: st.caption(log)
        else: st.warning(log.replace("‚ö†Ô∏è", ""))
            
    st.markdown("---")
    st.info("**Y√™u c·∫ßu n√¢ng cao:**\n1. Label Spreading (Graph)\n2. Dynamic Threshold (FlexMatch)")

# =========================================================
# 5. DASHBOARD CH√çNH (FULL TABS)
# =========================================================
st.title("üõ°Ô∏è Trung t√¢m Gi√°m s√°t & D·ª± b√°o AQI")
tab1, tab2, tab3 = st.tabs(["üèÜ T·ªîNG H·ª¢P & SO S√ÅNH", "üî¨ PH√ÇN T√çCH K·ª∏ THU·∫¨T", "üö® C·∫¢NH B√ÅO (6 M·ª®C)"])

# --- TAB 1: SO S√ÅNH HI·ªÜU NƒÇNG ---
with tab1:
    st.header("1. K·∫øt qu·∫£ Th·ª±c nghi·ªám & So s√°nh")
    
    # T√¨m k·∫øt qu·∫£ Self-training t·ªët nh·∫•t
    best_self_acc = 0
    best_tau = "N/A"
    if db["self_experiments"]:
        for tau, res in db["self_experiments"].items():
            if res['test_metrics']['accuracy'] > best_self_acc:
                best_self_acc = res['test_metrics']['accuracy']
                best_tau = tau
    
    co_acc = db['co_training']['test_metrics']['accuracy'] if db['co_training'] else 0
    baseline = db['baseline']

    # KPI Row 1: C∆° b·∫£n
    c1, c2, c3 = st.columns(3)
    c1.metric("Baseline", f"{baseline:.1%}", "Supervised")
    c2.metric(f"Self-Train (œÑ={best_tau})", f"{best_self_acc:.1%}", f"{best_self_acc-baseline:+.1%}", delta_color="normal")
    c3.metric("Co-Training", f"{co_acc:.1%}", f"{co_acc-baseline:+.1%}", delta_color="inverse")

    # KPI Row 2: Bonus (N√¢ng cao)
    if db["label_spreading"] or db["dynamic_threshold"]:
        st.write("---")
        cb1, cb2 = st.columns(2)
        if db["label_spreading"]:
            acc = db["label_spreading"]["test_metrics"]["accuracy"]
            cb1.metric("Label Spreading (Graph)", f"{acc:.1%}", f"{acc-baseline:+.1%}")
        if db["dynamic_threshold"]:
            acc = db["dynamic_threshold"]["test_metrics"]["accuracy"]
            cb2.metric("Dynamic Threshold (FlexMatch)", f"{acc:.1%}", f"{acc-baseline:+.1%}")

    st.divider()
    
    # BI·ªÇU ƒê·ªí T·ªîNG H·ª¢P 4 C·ªòT M√ÄU
    col_chart, col_text = st.columns([2, 1])
    with col_chart:
        models = ["Baseline", "Co-Training"]
        scores = [baseline, co_acc]
        colors = ["#BDBDBD", "#EF5350"]
        
        # Self-training
        for tau, res in db["self_experiments"].items():
            models.append(f"Self-Train (œÑ={tau})")
            scores.append(res['test_metrics']['accuracy'])
            colors.append("#66BB6A" if tau == best_tau else "#A5D6A7")

        # Bonus 1: Label Spreading
        if db["label_spreading"]:
            models.append("Label Spreading")
            scores.append(db["label_spreading"]["test_metrics"]["accuracy"])
            colors.append("#29B6F6") # Xanh d∆∞∆°ng
            
        # Bonus 2: Dynamic Threshold
        if db["dynamic_threshold"]:
            models.append("Dynamic Threshold")
            scores.append(db["dynamic_threshold"]["test_metrics"]["accuracy"])
            colors.append("#7E57C2") # T√≠m

        fig = go.Figure(data=[go.Bar(
            x=models, y=scores, text=[f"{s:.1%}" for s in scores],
            textposition='auto', marker_color=colors
        )])
        fig.update_layout(title="So s√°nh Hi·ªáu nƒÉng (Accuracy)", yaxis_title="Accuracy")
        st.plotly_chart(fig, use_container_width=True)

    with col_text:
        st.subheader("üí° Nh·∫≠n x√©t")
        st.success(f"‚úÖ Self-training (œÑ={best_tau}) c·∫£i thi·ªán ƒë√°ng k·ªÉ.")
        if db["label_spreading"]:
            st.info("üîπ Label Spreading t·∫≠n d·ª•ng t·ªët c·∫•u tr√∫c ƒë·ªì th·ªã.")
        if db["dynamic_threshold"]:
            st.info("üîπ Dynamic Threshold x·ª≠ l√Ω t·ªët c√°c l·ªõp hi·∫øm.")

# --- TAB 2: PH√ÇN T√çCH CHUY√äN S√ÇU ---
with tab2:
    st.header("2. Ph√¢n t√≠ch Dynamics")
    c_left, c_right = st.columns(2)
    
    with c_left:
        st.subheader("üöÄ Self-Training Progress")
        if db["self_experiments"]:
            fig_line = go.Figure()
            for tau, res in db["self_experiments"].items():
                h = pd.DataFrame(res['history'])
                fig_line.add_trace(go.Scatter(x=h['iter'], y=h['val_f1_macro'], mode='lines+markers', name=f'Tau={tau}'))
            fig_line.update_layout(title="F1-Macro theo Iteration", xaxis_title="Iter", yaxis_title="F1")
            st.plotly_chart(fig_line, use_container_width=True)
        else: st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu Self-training.")
            
    with c_right:
        st.subheader("ü§ù Co-Training Analysis (Dual-Axis)")
        if db["co_training"]:
            h = pd.DataFrame(db["co_training"]['history'])
            fig_dual = go.Figure()
            # Tr·ª•c 1: Acc (ƒê∆∞·ªùng ƒë·ªè)
            fig_dual.add_trace(go.Scatter(x=h['iter'], y=h['val_accuracy'], name="Accuracy", line=dict(color='red', width=3)))
            # Tr·ª•c 2: S·ªë nh√£n gi·∫£ (C·ªôt x√°m)
            if 'new_pseudo' in h.columns:
                fig_dual.add_trace(go.Bar(x=h['iter'], y=h['new_pseudo'], name="Nh√£n gi·∫£", marker_color='lightgrey', opacity=0.5, yaxis='y2'))
            
            fig_dual.update_layout(
                title="T√°c ƒë·ªông c·ªßa Nh√£n gi·∫£ (Pseudo-labels) ƒë·∫øn Accuracy",
                yaxis=dict(title="Accuracy"),
                yaxis2=dict(title="S·ªë l∆∞·ª£ng nh√£n gi·∫£", overlaying='y', side='right'),
                legend=dict(x=0, y=1.1, orientation='h')
            )
            st.plotly_chart(fig_dual, use_container_width=True)
        else: st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu Co-training.")

    st.divider()
    with st.expander("üîç Chi ti·∫øt c·∫•u h√¨nh View Co-training"):
        v1, v2 = st.columns(2)
        with v1: 
            st.markdown("**View 1: Spatio-Temporal**")
            if db['co_training']: st.code(", ".join(db['co_training'].get('views', {}).get('view1', [])))
        with v2:
            st.markdown("**View 2: Meteo-Chemical**")
            if db['co_training']: st.code(", ".join(db['co_training'].get('views', {}).get('view2', [])))
            

# --- TAB 3: C·∫¢NH B√ÅO TH√îNG MINH & B·ªò L·ªåC ƒêA CHI·ªÄU ---
with tab3:
    st.header("3. H·ªá th·ªëng C·∫£nh b√°o S·ªõm & Khuy·∫øn ngh·ªã Y t·∫ø")
    
    if db["alerts"] is not None:
        df = db["alerts"]
        
        # -------------------------------------------------------------
        # 1. X·ª¨ L√ù D·ªÆ LI·ªÜU: √Ånh x·∫° sang 6 c·∫•p ƒë·ªô chu·∫©n
        # -------------------------------------------------------------
        aqi_details = {
            5: {"label": "Nguy h·∫°i (Hazardous)", "color": "#7E0023", "icon": "‚ò†Ô∏è", "score": 100, 
                "general": "üö® B√ÅO ƒê·ªòNG: Tr√°nh ho√†n to√†n ra ngo√†i.", "sensitive": "üè• C·∫§P C·ª®U: ·ªû y√™n trong ph√≤ng k√≠n c√≥ l·ªçc kh√≠."},
            4: {"label": "R·∫•t x·∫•u (Very Unhealthy)", "color": "#8f3f97", "icon": "üü£", "score": 80, 
                "general": "üö´ C·∫¢NH B√ÅO: Tr√°nh v·∫≠n ƒë·ªông m·∫°nh.", "sensitive": "üö´ C·∫§M: Kh√¥ng ra ngo√†i. Ng∆∞·ªùi gi√†/tr·∫ª em ·ªü nh√†."},
            3: {"label": "X·∫•u (Unhealthy)", "color": "#ff0000", "icon": "üî¥", "score": 60, 
                "general": "‚ö†Ô∏è Gi·∫£m th·ªùi gian ·ªü ngo√†i tr·ªùi.", "sensitive": "üò∑ B·∫ÆT BU·ªòC: ƒêeo kh·∫©u trang, tr√°nh ra ngo√†i."},
            2: {"label": "K√©m (Sensitive)", "color": "#ff7e00", "icon": "üü†", "score": 40, 
                "general": "üëå B√¨nh th∆∞·ªùng, nh∆∞ng ƒë·ªÅ ph√≤ng.", "sensitive": "üíä L∆ØU √ù: Gi·∫£m v·∫≠n ƒë·ªông, mang thu·ªëc d·ª± ph√≤ng."},
            1: {"label": "Trung b√¨nh (Moderate)", "color": "#ffff00", "icon": "üü°", "score": 20, 
                "general": "‚úÖ Ch·∫•p nh·∫≠n ƒë∆∞·ª£c.", "sensitive": "üå¨Ô∏è H·∫°n ch·∫ø m·ªü c·ª≠a s·ªï qu√° l√¢u."},
            0: {"label": "T·ªët (Good)", "color": "#00e400", "icon": "üü¢", "score": 0, 
                "general": "üéâ T·∫≠n h∆∞·ªüng kh√¥ng kh√≠ trong l√†nh!", "sensitive": "üòä An to√†n tuy·ªát ƒë·ªëi."}
        }

        # H√†m logic
        def process_aqi_logic(row):
            val = row.get('y_pred') if 'y_pred' in row else row.get('severity_rank')
            if val is None: val = 0 
            
            # Chu·∫©n h√≥a input
            v_str = str(val).lower()
            level = 0
            if "nguy h·∫°i" in v_str or "hazardous" in v_str or str(val)=="5": level = 5
            elif "r·∫•t x·∫•u" in v_str or "very" in v_str or str(val)=="4": level = 4
            elif "x·∫•u" in v_str or "unhealthy" in v_str or str(val)=="3": level = 3
            elif "k√©m" in v_str or "sensitive" in v_str or str(val)=="2": level = 2
            elif "trung b√¨nh" in v_str or "moderate" in v_str or str(val)=="1": level = 1
            
            info = aqi_details[level]
            return pd.Series([info['label'], info['score'], info['general'], info['sensitive']])

        # √Åp d·ª•ng logic (T·∫°o c·ªôt m·ªõi ƒë·ªÉ l·ªçc v√† hi·ªÉn th·ªã)
        target_col = next((c for c in ['severity_rank', 'y_pred', 'prediction'] if c in df.columns), None)
        if target_col:
            df[['M·ª©c ƒë·ªô', 'ƒêi·ªÉm nghi√™m tr·ªçng', 'H√†nh ƒë·ªông (Chung)', 'H√†nh ƒë·ªông (Nh√≥m nh·∫°y c·∫£m)']] = df.apply(process_aqi_logic, axis=1)
        else:
            st.error("D·ªØ li·ªáu thi·∫øu c·ªôt d·ª± b√°o.")
            st.stop()

        # -------------------------------------------------------------
        # 2. B·ªò L·ªåC & TH·ªêNG K√ä (K√ä KHAI)
        # -------------------------------------------------------------
        f1, f2, f3 = st.columns([1, 1, 2])
        
        # A. B·ªô l·ªçc
        with f1:
            stations = ["T·∫•t c·∫£"] + sorted(list(df['station'].astype(str).unique()))
            sel_station = st.selectbox("üìç Ch·ªçn Tr·∫°m:", stations)
            
        with f2:
            # Danh s√°ch m·ª©c ƒë·ªô ƒë·ªÉ l·ªçc
            level_options = ["T·∫•t c·∫£"] + [aqi_details[i]['label'] for i in range(5, -1, -1)]
            sel_level = st.selectbox("‚ö†Ô∏è Ch·ªçn M·ª©c ƒë·ªô:", level_options)

        # B. Logic L·ªçc d·ªØ li·ªáu
        df_view = df.copy()
        if sel_station != "T·∫•t c·∫£": 
            df_view = df_view[df_view['station'] == sel_station]
        if sel_level != "T·∫•t c·∫£":
            df_view = df_view[df_view['M·ª©c ƒë·ªô'] == sel_level]

        # S·∫Øp x·∫øp: Nguy hi·ªÉm nh·∫•t l√™n ƒë·∫ßu
        df_view = df_view.sort_values(by='ƒêi·ªÉm nghi√™m tr·ªçng', ascending=False)

        # C. K√™ khai (Th·ªëng k√™) - Hi·ªÉn th·ªã ngay b√™n c·∫°nh b·ªô l·ªçc
        with f3:
            k1, k2, k3 = st.columns(3)
            k1.metric("T·ªïng b·∫£n ghi", len(df_view))
            
            # ƒê·∫øm s·ªë l∆∞·ª£ng nguy hi·ªÉm (M·ª©c >= 60 ƒëi·ªÉm: ƒê·ªè, T√≠m, N√¢u)
            n_danger = len(df_view[df_view['ƒêi·ªÉm nghi√™m tr·ªçng'] >= 60])
            k2.metric("M·ª©c ƒê·ªè/T√≠m/N√¢u", n_danger, delta="C·∫ßn x·ª≠ l√Ω" if n_danger > 0 else "An to√†n", delta_color="inverse")
            
            last_time = df_view['datetime'].max() if 'datetime' in df_view.columns else "N/A"
            k3.metric("C·∫≠p nh·∫≠t l√∫c", str(last_time))

        st.divider()

        # -------------------------------------------------------------
        # 3. B·∫¢NG HI·ªÇN TH·ªä TH√îNG MINH (Smart Table)
        # -------------------------------------------------------------
        if not df_view.empty:
            st.write(f"#### üìã Danh s√°ch chi ti·∫øt ({len(df_view)} b·∫£n ghi)")
            
            display_cols = ['station', 'datetime', 'M·ª©c ƒë·ªô', 'ƒêi·ªÉm nghi√™m tr·ªçng', 'H√†nh ƒë·ªông (Chung)', 'H√†nh ƒë·ªông (Nh√≥m nh·∫°y c·∫£m)']
            
            st.dataframe(
                df_view[display_cols],
                use_container_width=True,
                column_config={
                    "datetime": st.column_config.DatetimeColumn("Th·ªùi gian", format="D MMM, HH:mm"),
                    "M·ª©c ƒë·ªô": st.column_config.TextColumn("C·∫•p ƒë·ªô AQI", help="Ph√¢n lo·∫°i chu·∫©n EPA"),
                    "ƒêi·ªÉm nghi√™m tr·ªçng": st.column_config.ProgressColumn(
                        "Thanh M·ª©c ƒë·ªô",
                        help="Thanh c√†ng d√†i c√†ng nguy hi·ªÉm (0-100)",
                        format="%d/100",
                        min_value=0, max_value=100,
                    ),
                    "H√†nh ƒë·ªông (Chung)": st.column_config.TextColumn("üåç Khuy·∫øn ngh·ªã c·ªông ƒë·ªìng"),
                    "H√†nh ƒë·ªông (Nh√≥m nh·∫°y c·∫£m)": st.column_config.TextColumn("üè• Nh√≥m nh·∫°y c·∫£m"),
                },
                hide_index=True,
                height=600
            )
        else:
            st.info(f"‚úÖ Kh√¥ng t√¨m th·∫•y b·∫£n ghi n√†o th·ªèa m√£n ƒëi·ªÅu ki·ªán l·ªçc.")

        # Ch√∫ th√≠ch
        with st.expander("‚ÑπÔ∏è H∆∞·ªõng d·∫´n ƒë·ªçc ch·ªâ s·ªë & M√†u s·∫Øc"):
            st.markdown("""
            * **ƒêi·ªÉm nghi√™m tr·ªçng:** 0 (T·ªët) -> 100 (Nguy h·∫°i).
            * **Nh√≥m nh·∫°y c·∫£m:** Ng∆∞·ªùi gi√†, tr·∫ª em, ng∆∞·ªùi m·∫Øc b·ªánh h√¥ h·∫•p/tim m·∫°ch.
            * **L·ªçc:** S·ª≠ d·ª•ng 2 √¥ ch·ªçn ph√≠a tr√™n ƒë·ªÉ thu h·∫πp ph·∫°m vi t√¨m ki·∫øm.
            """)
            
    else:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu C·∫£nh b√°o.")